{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qPJOqecjULpi"
      },
      "id": "qPJOqecjULpi",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = os.path.dirname(\"/content/fear_greed_index.csv\")\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"csv_files\")\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"outputs\")\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "plt.style.use('seaborn-v0_8')"
      ],
      "metadata": {
        "id": "euB9cpSqUmjq"
      },
      "id": "euB9cpSqUmjq",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fg_path = os.path.join(\"/content\", \"fear_greed_index.csv\")\n",
        "trades_path = os.path.join(\"/content\", \"historical_data.csv\")\n",
        "fear_greed = pd.read_csv(fg_path)\n",
        "historical = pd.read_csv(trades_path)\n",
        "required_fg = {\"date\", \"classification\", \"value\"}\n",
        "missing_fg = required_fg - set(fear_greed.columns)\n",
        "if missing_fg:\n",
        "    raise KeyError(f\"Fear/Greed CSV missing required columns: {missing_fg}\")\n",
        "lower = {c.lower().strip(): c for c in historical.columns}\n",
        "def resolve(candidates):\n",
        "    for key in candidates:\n",
        "        if key in lower:\n",
        "            return lower[key]\n",
        "    return None\n",
        "time_col = resolve([\"time\",\"timestamp\",\"timestamp ist\"])\n",
        "pnl_col = resolve([\"closedpnl\",\"closed pnl\",\"pnl\",\"closed_pnl\"])\n",
        "side_col = resolve([\"side\"])\n",
        "size_col = resolve([\"size usd\",\"size tokens\",\"size\"])\n",
        "lev_col = resolve([\"leverage\"])\n",
        "if None in {time_col, pnl_col, side_col, size_col}:\n",
        "    raise KeyError(\"Historical CSV missing required trading columns\")\n",
        "fear_greed[\"date\"] = pd.to_datetime(fear_greed[\"date\"], errors=\"raise\")\n",
        "tc = historical[time_col]\n",
        "if pd.api.types.is_numeric_dtype(tc):\n",
        "    med = np.nanmedian(tc.astype(float)) if len(tc) else np.nan\n",
        "    unit = None\n",
        "    if np.isfinite(med):\n",
        "        if med > 1e16:\n",
        "            unit = \"ns\"\n",
        "        elif med > 1e14:\n",
        "            unit = \"us\"\n",
        "        elif med > 1e11:\n",
        "            unit = \"ms\"\n",
        "        elif med > 1e8:\n",
        "            unit = \"s\"\n",
        "    historical[time_col] = pd.to_datetime(tc, unit=unit) if unit else pd.to_datetime(tc, errors=\"coerce\")\n",
        "else:\n",
        "    coerce_num = pd.to_numeric(tc, errors=\"coerce\")\n",
        "    if coerce_num.notna().mean() > 0.8:\n",
        "        med = np.nanmedian(coerce_num)\n",
        "        unit = None\n",
        "        if np.isfinite(med):\n",
        "            if med > 1e16:\n",
        "                unit = \"ns\"\n",
        "            elif med > 1e14:\n",
        "                unit = \"us\"\n",
        "            elif med > 1e11:\n",
        "                unit = \"ms\"\n",
        "            elif med > 1e8:\n",
        "                unit = \"s\"\n",
        "        historical[time_col] = pd.to_datetime(coerce_num, unit=unit) if unit else pd.to_datetime(tc, errors=\"coerce\")\n",
        "    else:\n",
        "        historical[time_col] = pd.to_datetime(tc, errors=\"coerce\")\n",
        "if historical[time_col].isna().all():\n",
        "    raise ValueError(f\"Could not parse timestamps in column '{time_col}'\")\n",
        "historical[\"date\"] = historical[time_col].dt.normalize()\n",
        "historical[pnl_col] = pd.to_numeric(historical[pnl_col], errors=\"coerce\")\n",
        "historical[size_col] = pd.to_numeric(historical[size_col], errors=\"coerce\")\n",
        "if lev_col is not None:\n",
        "    historical[lev_col] = pd.to_numeric(historical[lev_col], errors=\"coerce\")\n",
        "historical[\"is_win\"] = (historical[pnl_col] > 0).astype(int)\n",
        "historical[\"abs_size\"] = historical[size_col].abs()\n",
        "agg = {\n",
        "    pnl_col: [\"sum\",\"mean\",\"std\", lambda s: s.quantile(0.10)],\n",
        "    \"abs_size\": [\"sum\",\"mean\"],\n",
        "    \"is_win\": [\"mean\"]\n",
        "}\n",
        "if lev_col is not None:\n",
        "    agg[lev_col] = [\"median\",\"mean\"]\n",
        "daily_grp = historical.groupby(\"date\").agg(agg)\n",
        "daily_grp.columns = [\"_\".join([c for c in col if c]) for col in daily_grp.columns.to_flat_index()]\n",
        "daily_grp = daily_grp.rename(columns={\n",
        "    f\"{pnl_col}_sum\":\"daily_pnl_sum\",\n",
        "    f\"{pnl_col}_mean\":\"daily_pnl_mean\",\n",
        "    f\"{pnl_col}_std\":\"daily_pnl_std\",\n",
        "    f\"{pnl_col}_<lambda_0>\":\"daily_pnl_p10\",\n",
        "    \"abs_size_sum\":\"total_volume\",\n",
        "    \"abs_size_mean\":\"avg_trade_size\",\n",
        "    \"is_win_mean\":\"win_rate\"\n",
        "})\n",
        "if lev_col is not None:\n",
        "    daily_grp = daily_grp.rename(columns={\n",
        "        f\"{lev_col}_median\":\"median_leverage\",\n",
        "        f\"{lev_col}_mean\":\"avg_leverage\"\n",
        "    })\n",
        "daily_side = (\n",
        "    historical.groupby([\"date\",side_col]).size()\n",
        "    .groupby(level=0).apply(lambda s: s / s.sum())\n",
        "    .unstack(fill_value=0)\n",
        ").add_prefix(\"side_share_\")\n",
        "joined = daily_grp.join(daily_side, how=\"left\").merge(\n",
        "    fear_greed[[\"date\",\"classification\",\"value\"]].set_index(\"date\"),\n",
        "    left_index=True, right_index=True, how=\"left\"\n",
        ").sort_index()\n",
        "if isinstance(joined.index, pd.MultiIndex):\n",
        "    joined.index = joined.index.get_level_values(0)\n",
        "joined_reset = joined.reset_index()\n",
        "joined_reset.to_csv(os.path.join(DATA_DIR, \"daily_metrics_with_sentiment.csv\"), index=False)\n",
        "aligned = joined.copy()\n",
        "if aligned[\"daily_pnl_sum\"].std(ddof=0) != 0:\n",
        "    aligned[\"pnl_z\"] = (aligned[\"daily_pnl_sum\"] - aligned[\"daily_pnl_sum\"].mean()) / aligned[\"daily_pnl_sum\"].std(ddof=0)\n",
        "else:\n",
        "    aligned[\"pnl_z\"] = 0.0\n",
        "if aligned[\"value\"].std(ddof=0) != 0:\n",
        "    aligned[\"sentiment_z\"] = (aligned[\"value\"] - aligned[\"value\"].mean()) / aligned[\"value\"].std(ddof=0)\n",
        "else:\n",
        "    aligned[\"sentiment_z\"] = 0.0\n",
        "aligned[\"alignment_score\"] = aligned[\"pnl_z\"] * aligned[\"sentiment_z\"]\n",
        "aligned[\"pnl_direction\"] = aligned[\"daily_pnl_sum\"].diff().apply(lambda x: np.sign(x) if pd.notna(x) else 0)\n",
        "aligned[\"sentiment_direction\"] = aligned[\"value\"].diff().apply(lambda x: np.sign(x) if pd.notna(x) else 0)\n",
        "aligned[\"directional_alignment\"] = np.where(aligned[\"pnl_direction\"] == aligned[\"sentiment_direction\"], 1, -1)\n",
        "aligned[\"alignment_flag\"] = np.where(\n",
        "    aligned[\"alignment_score\"] > 0,\n",
        "    \"Aligned\",\n",
        "    np.where(aligned[\"alignment_score\"] < 0, \"Divergent\", \"Neutral\")\n",
        ")\n",
        "aligned[\"net_alignment\"] = aligned[\"alignment_score\"] * aligned[\"directional_alignment\"]\n",
        "classification_map = {\n",
        "    \"Extreme Fear\": -2,\n",
        "    \"Fear\": -1,\n",
        "    \"Neutral\": 0,\n",
        "    \"Greed\": 1,\n",
        "    \"Extreme Greed\": 2\n",
        "}\n",
        "aligned[\"classification_score\"] = aligned[\"classification\"].map(classification_map)\n",
        "aligned_reset = aligned.reset_index()\n",
        "aligned_reset.to_csv(os.path.join(DATA_DIR, \"daily_alignment_metrics.csv\"), index=False)\n",
        "alignment_summary = aligned.groupby(\"classification\", dropna=False).agg({\n",
        "    \"alignment_score\": \"mean\",\n",
        "    \"net_alignment\": \"mean\",\n",
        "    \"daily_pnl_sum\": \"mean\",\n",
        "    \"value\": \"mean\"\n",
        "}).rename(columns={\n",
        "    \"alignment_score\": \"avg_alignment\",\n",
        "    \"net_alignment\": \"avg_net_alignment\",\n",
        "    \"daily_pnl_sum\": \"avg_daily_pnl\",\n",
        "    \"value\": \"avg_sentiment_value\"\n",
        "})\n",
        "alignment_summary.to_csv(os.path.join(DATA_DIR, \"alignment_summary_by_class.csv\"))\n",
        "sns.scatterplot(data=aligned, x=\"sentiment_z\", y=\"pnl_z\", hue=\"classification\")\n",
        "plt.axhline(0, color=\"gray\", linewidth=1)\n",
        "plt.axvline(0, color=\"gray\", linewidth=1)\n",
        "plt.title(\"Sentiment vs PnL (Z-scores)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"scatter_sentiment_vs_pnl_z.png\"), dpi=150)\n",
        "plt.close()\n",
        "sns.barplot(data=aligned_reset, x=\"alignment_flag\", y=\"daily_pnl_sum\", estimator=np.mean, order=[\"Aligned\",\"Neutral\",\"Divergent\"])\n",
        "plt.title(\"Average Daily PnL by Alignment Flag\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"bar_alignment_flag_pnl.png\"), dpi=150)\n",
        "plt.close()\n",
        "heat = aligned.pivot_table(index=\"classification\", columns=\"alignment_flag\", values=\"alignment_score\", aggfunc=\"mean\")\n",
        "sns.heatmap(heat, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar_kws={\"label\":\"Mean Alignment Score\"})\n",
        "plt.title(\"Alignment Score by Sentiment Class and Flag\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"heatmap_alignment_by_class.png\"), dpi=150)\n",
        "plt.close()\n",
        "print(\"daily_metrics_with_sentiment.csv saved\")\n",
        "print(\"daily_alignment_metrics.csv saved\")\n",
        "print(\"alignment_summary_by_class.csv saved\")\n",
        "print(\"plots saved in outputs/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDZ4gC2pUoZa",
        "outputId": "e71bee9a-efe6-4803-924e-73c74bf5c974"
      },
      "id": "WDZ4gC2pUoZa",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2156088779.py:4: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  historical = pd.read_csv(trades_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "daily_metrics_with_sentiment.csv saved\n",
            "daily_alignment_metrics.csv saved\n",
            "alignment_summary_by_class.csv saved\n",
            "plots saved in outputs/\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}